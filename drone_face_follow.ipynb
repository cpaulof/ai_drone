{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5e9b9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import asyncio\n",
    "#from mavsdk import System\n",
    "import mediapipe as mp\n",
    "import PIL\n",
    "from PIL import ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7b315c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drone =  System(mavsdk_server_address='localhost', port=50051)\n",
    "\n",
    "model = mp.solutions.face_detection.FaceDetection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03f8d54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def setup():\n",
    "    await drone.connect(system_address=\"udp://:14540\")\n",
    "    \n",
    "    print(\"Waiting for drone to connect...\")\n",
    "    async for state in drone.core.connection_state():\n",
    "        if state.is_connected:\n",
    "            print(f\"-- Connected to drone!\")\n",
    "            break\n",
    "    \n",
    "    print(\"Waiting for drone to have a global position estimate...\")\n",
    "    async for health in drone.telemetry.health():\n",
    "        if health.is_global_position_ok and health.is_home_position_ok:\n",
    "            print(\"-- Global position estimate OK\")\n",
    "            break\n",
    "    \n",
    "    print(\"-- Arming\")\n",
    "    await drone.action.arm()\n",
    "    \n",
    "    print(\"-- Taking off\")\n",
    "    await drone.action.takeoff()\n",
    "\n",
    "    await asyncio.sleep(5)\n",
    "    \n",
    "    print(\"-- Starting manual control\")\n",
    "    await drone.manual_control.start_position_control()\n",
    "    print('Drone Ready!')\n",
    "    \n",
    "\n",
    "def move_vert(d):\n",
    "    #await drone.manual_control.set_manual_control_input(0.0, 0.0, d, 0.)\n",
    "    m = ''\n",
    "    if d > 0:\n",
    "        m = 'move up'\n",
    "    elif d<0:\n",
    "        m = 'move down'\n",
    "    print(m)\n",
    "    \n",
    "def move_hori(d):\n",
    "    #await drone.manual_control.set_manual_control_input(0.0, 0.0, 0.0, d)\n",
    "    m = ''\n",
    "    if d > 0:\n",
    "        m = 'move right'\n",
    "    elif d<0:\n",
    "        m = 'move left'\n",
    "    print(m)\n",
    "\n",
    "# t\n",
    "def _capture():\n",
    "    return np.array(PIL.Image.open('face/face.jpg'), 'uint8')\n",
    "\n",
    "def main():\n",
    "    img_array = _capture()\n",
    "    d1, d2 = predict(img_array)\n",
    "    move_hori(d1)\n",
    "    move_vert(d2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "33284324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_pb2(pb2):\n",
    "    s = pb2.score[0]\n",
    "    x = pb2.location_data.relative_bounding_box.xmin\n",
    "    y = pb2.location_data.relative_bounding_box.ymin\n",
    "    w = pb2.location_data.relative_bounding_box.width\n",
    "    h = pb2.location_data.relative_bounding_box.height\n",
    "    return (s, x, y, w, h)\n",
    "\n",
    "def detect(img_path_or_array):\n",
    "    if isinstance(img_path_or_array, str):\n",
    "        img_array = PIL.Image.open(file_path_or_array)\n",
    "        img_array = np.array(img, dtype='uint8')\n",
    "    else:\n",
    "        img_array = img_path_or_array\n",
    "    \n",
    "    r = model.process(img_array)\n",
    "    if r.detections is None:\n",
    "        return None\n",
    "    r = np.array([parse_pb2(i) for i in r.detections])\n",
    "    best = r[np.argmax(r[...,0], axis=-1)]\n",
    "    h = img_array.shape[-3]\n",
    "    w = img_array.shape[-2]\n",
    "    best_score = best[0]\n",
    "    best_bbox = [w*best[1], h*best[2], w*best[3], h*best[4]]\n",
    "    return best_score, best_bbox\n",
    "\n",
    "\n",
    "def draw_bbox_on_image(img, bbox):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.rectangle([(bbox[0],bbox[1]),(bbox[0]+bbox[2],bbox[1]+bbox[3])], outline=(255,32,142), width=2)\n",
    "\n",
    "def detect_and_draw(filepath):\n",
    "    img = PIL.Image.open(filepath)\n",
    "    img_array = np.array(img, 'uint8')\n",
    "    try:\n",
    "        score, bbox = detect(img_array)\n",
    "        draw_bbox_on_image(img, bbox)\n",
    "        img.show()\n",
    "    except Exception as e:\n",
    "        print('error:', e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6d7bc419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(img_array):\n",
    "    r = detect(img_array)\n",
    "    if r is None:\n",
    "        return\n",
    "    s, b = r\n",
    "    img_size = img_array.shape[:2]\n",
    "    d1, d2 = get_direction_to_move(b, img_size)\n",
    "    return d1, d2\n",
    "    \n",
    "\n",
    "def get_direction_to_move(coords, img_size, th=0.2):\n",
    "    '''calcula quanto devera ser descolado vertical e horizontalmente'''\n",
    "    IMG_SIZE = img_size\n",
    "    if len(coords) != 4:\n",
    "        raise ValueError(f'invalid coordinates size {len(coords)}, expected 4 (x1,y1,x2,y2)')\n",
    "    \n",
    "    xmin, ymin, width, height = coords\n",
    "    \n",
    "    th_h = height*th # th*IMG_SIZE[0]\n",
    "    th_w = width*th # th*IMG_SIZE[1]\n",
    "    \n",
    "    x_center = xmin + width/2\n",
    "    y_center = ymin + height/2\n",
    "    \n",
    "    W_CENTER = IMG_SIZE[1]/2\n",
    "    H_CENTER = IMG_SIZE[0]/2\n",
    "    \n",
    "    D1 = 0\n",
    "    D2 = 0\n",
    "    \n",
    "    if x_center > W_CENTER and  x_center-W_CENTER >= th_w:\n",
    "        D1 += 0.5\n",
    "        \n",
    "    elif x_center < W_CENTER and W_CENTER-x_center >= th_w:\n",
    "        D1 -= 0.5\n",
    "    \n",
    "    if y_center > H_CENTER and y_center-H_CENTER >= th_h:\n",
    "        D2 -= 0.5\n",
    "    \n",
    "    elif y_center < H_CENTER and H_CENTER-y_center >= th_h:\n",
    "        D2 += 0.5\n",
    "    return D1, D2\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1ec093a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dcffef16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285.6197769641876"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14.280988848209383/0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578429ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
